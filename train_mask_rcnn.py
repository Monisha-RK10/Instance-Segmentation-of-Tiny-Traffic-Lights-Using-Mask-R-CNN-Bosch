# -*- coding: utf-8 -*-
"""train_mask_rcnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ievd8ckQ0sar_tvi7H0vBlGwb1jJDAIq
"""

import torchvision
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

# Import COCOMaskRCNNDataset from dataset/mask_rcnn_dataset
from dataset.mask_rcnn_dataset import COCOMaskRCNNDataset

def get_mask_rcnn_model(num_classes):
    # Load a pre-trained model for COCO
    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights="DEFAULT")

    # Replace the classifier head
    in_features_cls = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(
        in_features_cls, num_classes # Box classification is scalar -> linear layer
    )

    # Replace the mask predictor head
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    hidden_layer = 256
    model.roi_heads.mask_predictor = MaskRCNNPredictor(
        in_features_mask, hidden_layer, num_classes # Mask prediction is spatial -> CNN + upsampling → need hidden layers.

    )

    return model

import torch
import torchvision
import matplotlib.pyplot as plt
import time
import os
from tqdm import tqdm
from torch.utils.data import DataLoader
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torch.optim.lr_scheduler import ReduceLROnPlateau

# Paths
save_path = "best_maskrcnn.pth"

# Setup
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = get_mask_rcnn_model(num_classes=3)  # Background, Red, Green
model.to(device)

# Optimizer & LR scheduler
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.Adam(params, lr=1e-4)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True)

# Create dataset & dataloaders
train_dataset = COCOMaskRCNNDataset(
    images_dir='/content/drive/MyDrive/MASK-RCNN_TrafficLight/images/train',
    annotation_json='/content/drive/MyDrive/MASK-RCNN_TrafficLight/annotation_train.json',
    transforms=T.ToTensor()  # Or custom Compose
)
val_dataset = COCOMaskRCNNDataset(
    images_dir='/content/drive/MyDrive/MASK-RCNN_TrafficLight/images/val',
    annotation_json='/content/drive/MyDrive/MASK-RCNN_TrafficLight/annotation_val.json',
    transforms=T.ToTensor()
)

train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))

num_epochs = 40
train_losses, val_losses = [], []
best_val_loss = float('inf')
early_stop_patience = 10
epochs_no_improve = 0

for epoch in range(num_epochs):
    model.train()
    epoch_train_loss = 0

    for images, targets in tqdm(train_loader,  desc=f"Epoch {epoch+1} [Train]"):
        images = list(img.to(device) for img in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        loss_dict = model(images, targets)
        loss = sum(loss for loss in loss_dict.values()) #  Loss is a combination of: classification loss, box regression loss, mask segmentation loss, objectness loss, RPN loss

        optimizer.zero_grad() # Clears the previous gradients stored in the model’s parameters. Skipping zero_grad() would accumulate gradients from past steps (bad, unless explicitly doing gradient accumulation for large batch training).
        loss.backward() # Performs backpropagation: calculates gradients of the loss w.r.t model parameters.
        optimizer.step() # Updates model parameters using the gradients calculated.

        epoch_train_loss += loss.item()

    avg_train_loss = epoch_train_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # Validation step
    model.eval()  # Proper eval mode to disable dropout/batchnorm.
    epoch_val_loss = 0

    with torch.no_grad():
        for images, targets in val_loader:
            images = list(img.to(device) for img in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            model.train()  # TEMPORARILY switch for loss computation
            loss_dict = model(images, targets)
            loss = sum(loss for loss in loss_dict.values())
            model.eval()  # Switch back to eval to keep behavior consistent

            epoch_val_loss += loss.item()


    avg_val_loss = epoch_val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")

    # Scheduler step, adjusts the learning rate dynamically based on validation loss.
    scheduler.step(avg_val_loss) # If val_loss doesn’t improve for 20 epochs (patience=20), reduce the LR by half (factor=0.5).

    # Save best model
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(), # Contains only the weights, not architecture (reconstruct the model architecture and then load the weights).
            'optimizer_state_dict': optimizer.state_dict(), # To resume training with the same momentum,
            'val_loss': avg_val_loss
        }, save_path)
        print(f" Saved Best Model (Epoch {epoch+1})")
    else:
        epochs_no_improve += 1

    if epochs_no_improve == early_stop_patience:
        print(f"Early stopping at epoch {epoch+1}")
        break

# Plot loss curves
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs+1), train_losses, label="Train Loss")
plt.plot(range(1, num_epochs+1), val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training & Validation Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("loss_plot.png")
plt.show()